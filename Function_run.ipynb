{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo3_object_detection(net, classes, test_folder = 'wholeData3', destination_folder = 'img'):\n",
    "    layer_names = net.getLayerNames()\n",
    "    outputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    colors= np.random.uniform(0,255,size=(len(classes),3))\n",
    "    #loading image\n",
    "    import glob\n",
    "    #cap=cv2.VideoCapture(0) #0 for 1st webcam\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    starting_time= time.time()\n",
    "    frame_id = 0\n",
    "    save=0\n",
    "\n",
    "    for img_link in glob.glob(test_folder + '/*'):\n",
    "        #_,frame= cap.read() # \n",
    "        frame_id+=1\n",
    "        frame = cv2.imread(img_link)\n",
    "        height,width,channels = frame.shape\n",
    "        #detecting objects\n",
    "        blob = cv2.dnn.blobFromImage(frame,0.00392,(320,320),(0,0,0),True,crop=False) #reduce 416 to 320    \n",
    "\n",
    "        \n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(outputlayers)\n",
    "        #print(outs[1])\n",
    "\n",
    "\n",
    "        #Showing info on screen/ get confidence score of algorithm in detecting an object in blob\n",
    "        class_ids=[]\n",
    "        confidences=[]\n",
    "        boxes=[]\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.3:\n",
    "                    #onject detected\n",
    "                    center_x= int(detection[0]*width)\n",
    "                    center_y= int(detection[1]*height)\n",
    "                    w = int(detection[2]*width)\n",
    "                    h = int(detection[3]*height)\n",
    "\n",
    "                    #cv2.circle(img,(center_x,center_y),10,(0,255,0),2)\n",
    "                    #rectangle co-ordinaters\n",
    "                    x=int(center_x - w/2)\n",
    "                    y=int(center_y - h/2)\n",
    "                    #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "                    boxes.append([x,y,w,h]) #put all rectangle areas\n",
    "                    confidences.append(float(confidence)) #how confidence was that object detected and show that percentage\n",
    "                    class_ids.append(class_id) #name of the object tha was detected\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.4,0.6)\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x,y,w,h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence= confidences[i]\n",
    "                color = colors[class_ids[i]]\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),color,2)\n",
    "                cv2.putText(frame,label+\" \"+str(round(confidence,2)),(x,y+30),font,1,(255,255,255),2)\n",
    "            \n",
    "\n",
    "        elapsed_time = time.time() - starting_time\n",
    "        fps=elapsed_time/frame_id\n",
    "        print(fps)\n",
    "        cv2.putText(frame,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),1)\n",
    "    \n",
    "        cv2.imshow(\"Image\",frame)\n",
    "        cv2.imwrite(destination_folder + '/img' + str(save) + '.jpg',frame)\n",
    "        save+=1\n",
    "        key = cv2.waitKey(1) #wait 1ms the loop will start again and we will process the next frame\n",
    "    \n",
    "        if key == 27: #esc key stops the process\n",
    "            break;\n",
    "    \n",
    "    #cap.release()    \n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3-spp.weights\",\"yolov3-spp.cfg\") # Original yolov3\n",
    "#net = cv2.dnn.readNet(\"yolov3-tiny.weights\",\"yolov3-tiny.cfg\") #Tiny Yolo\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9324929714202881\n",
      "0.9532285928726196\n",
      "0.9365302721659342\n",
      "0.9009802937507629\n",
      "0.8650659561157227\n",
      "0.8513243993123373\n",
      "0.8406038965497699\n",
      "0.8385683298110962\n",
      "0.8270320627424452\n",
      "0.8664762020111084\n",
      "0.8706727244637229\n",
      "0.8837443590164185\n",
      "0.8833330777975229\n",
      "0.8787623132978167\n",
      "0.8729631106058756\n",
      "0.8721088320016861\n",
      "0.874395538778866\n",
      "0.8719672097100152\n",
      "0.869948336952611\n",
      "0.882173228263855\n"
     ]
    }
   ],
   "source": [
    "yolo3_object_detection( net, classes, 'wholeData3', 'img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolov3:\n",
    "    \n",
    "    def yolo3_object_detection(self, net, classes, test_folder = 'wholeData3', destination_folder = 'img'):\n",
    "        layer_names = net.getLayerNames()\n",
    "        outputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "        colors= np.random.uniform(0,255,size=(len(classes),3))\n",
    "        #loading image\n",
    "        import glob\n",
    "        #cap=cv2.VideoCapture(0) #0 for 1st webcam\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        starting_time= time.time()\n",
    "        frame_id = 0\n",
    "        save=0\n",
    "\n",
    "        for img_link in glob.glob(test_folder + '/*'):\n",
    "            #_,frame= cap.read() # \n",
    "            frame_id+=1\n",
    "            frame = cv2.imread(img_link)\n",
    "            height,width,channels = frame.shape\n",
    "            #detecting objects\n",
    "            blob = cv2.dnn.blobFromImage(frame,0.00392,(320,320),(0,0,0),True,crop=False) #reduce 416 to 320    \n",
    "\n",
    "        \n",
    "            net.setInput(blob)\n",
    "            outs = net.forward(outputlayers)\n",
    "            #print(outs[1])\n",
    "\n",
    "\n",
    "            #Showing info on screen/ get confidence score of algorithm in detecting an object in blob\n",
    "            class_ids=[]\n",
    "            confidences=[]\n",
    "            boxes=[]\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.3:\n",
    "                        #onject detected\n",
    "                        center_x= int(detection[0]*width)\n",
    "                        center_y= int(detection[1]*height)\n",
    "                        w = int(detection[2]*width)\n",
    "                        h = int(detection[3]*height)\n",
    "\n",
    "                        #cv2.circle(img,(center_x,center_y),10,(0,255,0),2)\n",
    "                        #rectangle co-ordinaters\n",
    "                        x=int(center_x - w/2)\n",
    "                        y=int(center_y - h/2)\n",
    "                        #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "                        boxes.append([x,y,w,h]) #put all rectangle areas\n",
    "                        confidences.append(float(confidence)) #how confidence was that object detected and show that percentage\n",
    "                        class_ids.append(class_id) #name of the object tha was detected\n",
    "\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.4,0.6)\n",
    "\n",
    "            for i in range(len(boxes)):\n",
    "                if i in indexes:\n",
    "                    x,y,w,h = boxes[i]\n",
    "                    label = str(classes[class_ids[i]])\n",
    "                    confidence= confidences[i]\n",
    "                    color = colors[class_ids[i]]\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),color,2)\n",
    "                    cv2.putText(frame,label+\" \"+str(round(confidence,2)),(x,y+30),font,1,(255,255,255),2)\n",
    "                \n",
    "\n",
    "            elapsed_time = time.time() - starting_time\n",
    "            fps=elapsed_time/frame_id\n",
    "            print(fps)\n",
    "            cv2.putText(frame,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),1)\n",
    "    \n",
    "            cv2.imshow(\"Image\",frame)\n",
    "            cv2.imwrite(destination_folder + '/img' + str(save) + '.jpg',frame)\n",
    "            save+=1\n",
    "            key = cv2.waitKey(1) #wait 1ms the loop will start again and we will process the next frame\n",
    "    \n",
    "            if key == 27: #esc key stops the process\n",
    "                break;\n",
    "    \n",
    "        #cap.release()    \n",
    "        cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5905580520629883\n",
      "0.7131557464599609\n",
      "0.8255808353424072\n",
      "0.8537926077842712\n",
      "0.9233726024627685\n",
      "0.9615087509155273\n",
      "0.991828441619873\n",
      "0.9617898762226105\n",
      "0.9358527130550809\n",
      "0.9119095087051392\n",
      "0.8956245075572621\n",
      "0.8808038632074991\n",
      "0.8672595024108887\n",
      "0.8717101301465716\n",
      "0.8635299682617188\n",
      "0.8675733357667923\n",
      "0.8680569564594942\n",
      "0.870157414012485\n",
      "0.867958759006701\n",
      "0.8603815197944641\n"
     ]
    }
   ],
   "source": [
    "new_obj = Yolov3()\n",
    "new_obj.yolo3_object_detection(net, classes, 'wholeData3', 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
